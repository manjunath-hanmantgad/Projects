{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d4fc75",
   "metadata": {},
   "source": [
    "## Building Machine learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a811ccf",
   "metadata": {},
   "source": [
    "- Data ingestion\n",
    "- Model training\n",
    "- Model testing\n",
    "- Model packaging\n",
    "- Model registering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a91bd",
   "metadata": {},
   "source": [
    "### Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f07cb",
   "metadata": {},
   "source": [
    "Data ingestion is a trigger step for the ML pipeline.\n",
    "import the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511afec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from math import sqrt\n",
    "warnings.filterwarnings('ignore')\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fe971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = ''\n",
    "resource_group = ''\n",
    "workspace_name = ''\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12566028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFLOW\n",
    "\n",
    "uri = workspace.get_mlflow_tracking_uri()\n",
    "mlflow.set_tracking_uri(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pre-processed dataset\n",
    "\n",
    "dataset = Dataset.get_by_name (workspace, name='processed_weather_data_portofTurku')\n",
    "\n",
    "print(dataset.name, dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f79cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas dataframe\n",
    "\n",
    "df = dataset.to_pandas_dataframe()\n",
    "\n",
    "# preview the first 3 rows of the dataset\n",
    "# df = dataset.take(3).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d5858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd35c6d",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df.iloc[:77160]\n",
    "\n",
    "df_validation = df.drop(df_training.index)\n",
    "\n",
    "df_training.to_csv('Dataset/training_data.csv',index=False)\n",
    "\n",
    "df_validation.to_csv('Dataset/validation_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100273ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6405b234",
   "metadata": {},
   "source": [
    "### After splitting the data, these two datasets are stored and registered to the datastore (connected to the Azure ML workspace) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir train_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_csv('train_val_dataset/training_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ec179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.to_csv('train_val_dataset/validation_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00de66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = workspace.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore.upload(src_dir='Dataset', target_path='train_val_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad378d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = Dataset.Tabular.from_delimited_files(datastore.path('train_val_dataset/training_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30695ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = Dataset.Tabular.from_delimited_files(datastore.path('train_val_dataset/validation_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will register training ds to our workpace\n",
    "training_ds = training_dataset.register(workspace=workspace,\n",
    "                                 name='training_dataset',\n",
    "                                 description='Dataset to use for ML training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad497b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will register validation ds  to our workpace\n",
    "validation_ds = validation_dataset.register(workspace=workspace,\n",
    "                                 name='validation_dataset',\n",
    "                                 description='Dataset for validation ML models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68a703",
   "metadata": {},
   "source": [
    "### Data ingestion (training dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7884f2",
   "metadata": {},
   "source": [
    "start by importing it using the get_by_name() function and converting it to a pandas dataframe using the to_pandas_dataframe() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name (workspace, name='training_dataset')\n",
    "print(dataset.name, dataset.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ab6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31734026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455a4fb",
   "metadata": {},
   "source": [
    "\n",
    "### Feature Selection and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d015292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .values so that the shape can be matched while transforming\n",
    "X = df[['Temperature_C', 'Humidity', 'Wind_speed_kmph', 'Wind_bearing_degrees', 'Visibility_km', 'Pressure_millibars', 'Current_weather_condition']].values\n",
    "y = df['Future_weather_condition'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddedb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6271e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Training dataset into Train and Test set for ML training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7071b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on test data only\n",
    "# fit_transform on train data !\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd958c",
   "metadata": {},
   "source": [
    "## Machine learning training and hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c98adb",
   "metadata": {},
   "source": [
    "The output of this step is a trained ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dad648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating the training or experiment using the Experiment() function from the Azure SDK. \n",
    "# The purpose of this function is to start a training run or experiment \n",
    "# in order to monitor and log the model training performance in the Azure ML workspace:\n",
    "\n",
    "myexperiment = Experiment(workspace, \"support-vector-machine\")\n",
    "mlflow.set_experiment(\"mlflow-support-vector-machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning to find the best parameters to converge the best model\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b187e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a run in Azureml and mlflow experiments\n",
    "run = myexperiment.start_logging()\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "run.log(\"dataset name\", dataset.name)\n",
    "\n",
    "run.log(\"dataset Version\", dataset.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf5364",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid = GridSearchCV(svc, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59081d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If deep=True, it will just return the parameters of the inner estimators if any\n",
    "svc_grid.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd097051",
   "metadata": {},
   "source": [
    "sklearn uses double underscore as separator. classifier key is the same as the pipeline name for estimator in the pipeline definition, classifier__C basically tells the grid searcher that we would like to try these provided values for C which is a parameter for the classifier to define regularization weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15954dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/ml-pipelines-with-grid-search-in-scikit-learn-2539d6b53cfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the best parameters, a new model is trained using C=1 and kernel='rbf '\n",
    "svc = SVC(C=svc_grid.get_params(deep=True)['estimator__C'], kernel=svc_grid.get_params(deep=True)['estimator__kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ba7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ef3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"C\", svc_grid.get_params(deep=True)['estimator__C'])\n",
    "run.log(\"Kernel\", svc_grid.get_params(deep=True)['estimator__kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with test data \n",
    "\n",
    "predicted_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd02534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, predicted_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ec85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore = f1_score(y_test, predicted_svc, average=\"macro\")\n",
    "precision = precision_score(y_test, predicted_svc, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_svc, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep track of hash histories\n",
    "\n",
    "import git\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "sha = repo.head.object.hexsha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to AzureML and MLflow\n",
    "\n",
    "run.log(\"Test_accuracy\", acc)\n",
    "run.log(\"Precision\", precision)\n",
    "run.log(\"Recall\", recall)\n",
    "run.log(\"F-Score\", fscore)\n",
    "run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.complete()\n",
    "print (\"run id:\", run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d1c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbbae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "mlflow.sklearn.log_model(svc, 'outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706c0ec",
   "metadata": {},
   "source": [
    "### Training with Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myexperiment = Experiment(workspace, \"random-forest-classifier\")\n",
    "mlflow.set_experiment(\"mlflow-random-forest-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a43eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually chosen as compute option is not large enough\n",
    "# for grid search on Random Forest need a bigger compute \n",
    "\n",
    "rf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize runs in Azureml and mlflow\n",
    "run = myexperiment.start_logging()\n",
    "mlflow.start_run()\n",
    "\n",
    "\n",
    "# Log dataset used \n",
    "run.log(\"dataset name\", dataset.name)\n",
    "run.log(\"dataset Version\", dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"max_depth\", 10)\n",
    "run.log(\"random_state\", 0)\n",
    "run.log(\"n_estimators\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57316d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with test data\n",
    "\n",
    "predicted_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, predicted_rf)\n",
    "fscore = f1_score(y_test, predicted_rf, average=\"macro\")\n",
    "precision = precision_score(y_test, predicted_rf, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_rf, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da27bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log(\"Test_accuracy\", acc)\n",
    "run.log(\"Precision\", precision)\n",
    "run.log(\"Recall\", recall)\n",
    "run.log(\"F-Score\", fscore)\n",
    "run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.complete()\n",
    "print (\"run id:\", run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51eac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59bee69",
   "metadata": {},
   "source": [
    "## Model Packaging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f78cf",
   "metadata": {},
   "source": [
    "ONNX offers an open standard for model interoperability. ONNX stands for Open Neural Network Exchange. It provides a serialization standard for importing and exporting models. We will use the ONNX format to serialize the models to avoid compatibility and interoperability issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9400d8e",
   "metadata": {},
   "source": [
    "Using ONNX, the trained model is serialized using the skl2onnx library. The model is serialized as the file svc.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into SVC model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(svc, initial_types=initial_type)\n",
    "with open(\"outputs/svc.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5304c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into RF model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(rf, initial_types=initial_type)\n",
    "with open(\"outputs/rf.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a74695",
   "metadata": {},
   "source": [
    "## Register these serialized models to the model registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871644a",
   "metadata": {},
   "source": [
    "A registered model is compiled as a logical container for one or more files that function as a model. For instance, a model made up of multiple files can be registered as a single model in the model registry. By downloading the registered model, all the files can be received. The registered model can be deployed and used for inference on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20543c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/svc.onnx', # this points to a local file \n",
    "                       model_name = \"support-vector-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9519'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Support vector classifier to predict\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/rf.onnx', # this points to a local file \n",
    "                       model_name = \"random-forest-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9548'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Random forest classifier to predict\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb742f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "mlflow.sklearn.log_model(svc, 'outputs/svc.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "mlflow.sklearn.log_model(rf, 'outputs/rf.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f3775",
   "metadata": {},
   "source": [
    "## Save model artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74a537",
   "metadata": {},
   "source": [
    "For model inference in real time, a scalar is needed in order to scale the incoming data on the scale at which the data was scaled for ML training. We will use the same scaler function used for scaling X_train using sc.fit_transform(X_train) and serialize this variable into a pickle file. Lastly, we register this pickle file to the workspace for further retrieval and usage as needed (especially for model inference in the test and production environment). Using pickle, write the scaler variable sc into a pickle file using the pickle.dump() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77335dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./outputs/scaler.pkl', 'wb') as scaler_pkl:\n",
    "    pickle.dump(sc, scaler_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5dbe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Model on AzureML WS\n",
    "scaler = Model.register(model_path = './outputs/scaler.pkl', # this points to a local file \n",
    "                       model_name = \"scaler\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Scaler used for scaling incoming inference data\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', scaler.name)\n",
    "print('Version:', scaler.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c4697d",
   "metadata": {},
   "source": [
    "## Both the SVM classifier and Random Forest classifier, along with the serialized scaler, are registered in the model registry. These models can be downloaded and deployed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfcb400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
