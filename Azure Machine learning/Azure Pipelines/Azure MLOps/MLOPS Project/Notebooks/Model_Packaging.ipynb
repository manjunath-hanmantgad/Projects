{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f103bf2",
   "metadata": {},
   "source": [
    "# Model Packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c65cd",
   "metadata": {},
   "source": [
    "- Model evaluation and interpretability metrics\n",
    "- Production testing methods\n",
    "- Package ML models\n",
    "- Inference ready models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8062fef",
   "metadata": {},
   "source": [
    "**Model evaluation and interpretability metrics** : They enable us to understand and validate the ML models to determine the business value they will produce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33dbd6",
   "metadata": {},
   "source": [
    "Commonly used metrics:\n",
    "\n",
    "- Cross-validation (stratified cross-validation, leave-one-out cross-validation, and K-fold cross-validation)\n",
    "//K-fold is not a good choice if you have a very large training dataset or if the model requires a large amount of time, CPU, and/or GPU processing for running.//\n",
    "\n",
    "- Precision\n",
    "\n",
    "- Recall\n",
    "\n",
    "- F score\n",
    "\n",
    "- Confusion matrix\n",
    "\n",
    "- AUc-ROC ( it uses TPR and FPR)\n",
    "//An ROC curve depicts the TPR versus FPR for different thresholds for classification. Lowering the threshold for classification enables more items to be classified as positive, which in turn increases both false positives and true positives. The Area Under the Curve (AUC) is a metric used to quantify the effectiveness or ability of a classifier to distinguish between classes and is used to summarize the ROC curve.//\n",
    "\n",
    "//the classifier is able to correctly distinguish between all the positive and negative class points if the AUC value is 1, and the classifier is unable to correctly distinguish between all the positive and negative class points if the AUC value is 0. When the AUC value is 0.5 (without manually setting a threshold), then this is a random classifier.//\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c48e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "from math import sqrt\n",
    "warnings.filterwarnings('ignore')\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf50b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacb7c03",
   "metadata": {},
   "source": [
    "## Download scaler and model from workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e285c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Model(ws,'scaler').download(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8dc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = Model(ws,'support-vector-classifier').download(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8b9d38",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21485ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the prediction with ONNX Runtime\n",
    "import onnxruntime as rt\n",
    "import numpy\n",
    "sess = rt.InferenceSession(\"svc.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a63270",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c80100e",
   "metadata": {},
   "source": [
    "## Inference on test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array([34.927778, 0.24, 7.3899, 83, 16.1000, 1])\n",
    "# these are values for Temperature_C, Humidity, Wind_speed_kmph, Wind_bearing_degrees, \n",
    "# Visibility_km, Pressure_millibars, and Current_weather_condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f878e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "test_data = scaler.fit_transform(test_data.reshape(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbbf734",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_onx = sess.run([label_name], {input_name: test_data.astype(numpy.float32)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40770348",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_onx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4b802",
   "metadata": {},
   "source": [
    "## Testing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb0a16",
   "metadata": {},
   "source": [
    "- Batch testing (The model is usually served as a serialized file, and the file is loaded as an object and inferred on test data.)\n",
    "\n",
    "- A/B testing ( Z-test, G-test)\n",
    "\n",
    "- Stage test or shadow test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690750d9",
   "metadata": {},
   "source": [
    "## Testing with CI/CD \n",
    "\n",
    "- Upon a successful run of an ML pipeline, CI/CD pipelines can trigger a new model's A/B test in the staging environment.\n",
    "\n",
    "- When a new model is trained, it is beneficial to set up a dataset separate from the test set to measure its performance against suitable metrics, and this step can be fully automated.\n",
    "\n",
    "- CI/CD pipelines can periodically trigger ML pipelines at a set time in a day to train a new model, which uses live or real-time data to train a new model or fine-tune an existing model.\n",
    "\n",
    "- CI/CD pipelines can monitor the ML model's performance of the deployed model in production, and this can be triggered or managed using time-based triggers or manual triggers (initiated by team members responsible for quality assurance).\n",
    "\n",
    "- CI/CD pipelines can provision two or more staging environments to perform A/B testing on unique datasets to perform more diverse and comprehensive testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea13da",
   "metadata": {},
   "source": [
    "## ML model packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da3813",
   "metadata": {},
   "source": [
    "In order to serve the models, they need to be packed into software artifacts to be shipped to the testing or production environments. Usually, these software artifacts are packaged into a file or a bunch of files or containers. This allows the software to be environment- and deployment-agnostic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349eb73",
   "metadata": {},
   "source": [
    "- packaged model can be deployed in a virtual machine or serverless setup , a container serverless environment, a streaming service, microservices, or batch services.\n",
    "\n",
    "- ML model interoperability is the ability of two or more models or components to exchange information and to use exchanged information in order to learn or fine-tune from each other and perform operations with efficiency. Exchanged information can be in the form of data or software artifacts or model parameters. Such information enables models to fine-tune, retrain, or adapt to various environments from the experience of other software artifacts in order to perform and be efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac49b9",
   "metadata": {},
   "source": [
    "## Ways to Packaage ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff433a",
   "metadata": {},
   "source": [
    "1. **Serialization** \n",
    "\n",
    "- is the method of converting an object or a data structure (for example, variables, arrays, and tuples) into a storable artefact, for example, into a file or a memory buffer that can be transported or transmitted (across computer networks). The main purpose of serialization is to reconstruct the serialized file into its previous data structure (for example, a serialized file into an ML model variable) in a different environment. This way, a newly trained ML model can be serialized into a file and exported into a new environment where it can de-serialized back into an ML model variable or data structure for ML inferencing.\n",
    "\n",
    "- examples: .pkl , .h5 , .onnx, .pb , .zip(for spark ML)\n",
    "\n",
    "\n",
    "2. **Packetizing or containerizing**\n",
    "\n",
    "- Using docker and Kubernetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd936851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
