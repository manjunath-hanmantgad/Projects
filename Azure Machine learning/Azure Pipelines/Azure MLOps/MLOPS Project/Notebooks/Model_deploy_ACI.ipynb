{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731f0d20",
   "metadata": {},
   "source": [
    "# Deploying ML models using ACI and AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd8269",
   "metadata": {},
   "source": [
    "Inference is performed on the serialized model on a container and an auto-scaling cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7413e6",
   "metadata": {},
   "source": [
    "1. deploying a REST API service on an Azure container instance using Azure ML\n",
    "\n",
    "2. deploy a REST API service on an auto-scaling cluster using Kubernetes (for container orchestration) using Azure ML\n",
    "\n",
    "3. deploy on an Azure container instance using MLflow and an open source ML framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1e552",
   "metadata": {},
   "source": [
    "# Deploying ML model as web service with Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import azureml.core\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize workspace\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f6fd3",
   "metadata": {},
   "source": [
    "## Scoring script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import onnxruntime\n",
    "import time\n",
    "from azureml.core.model import Model\n",
    "from azureml.monitoring import ModelDataCollector\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "\n",
    "def init():\n",
    "    global model, scaler, input_name, label_name, inputs_dc, prediction_dc\n",
    "    \n",
    "\n",
    "    scaler_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model-scaler/1/model-scaler.pkl')\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    model_onnx = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'support-vector-classifier/2/svc.onnx')\n",
    "    # print(os.listdir(model_onnx))\n",
    "    model = onnxruntime.InferenceSession(model_onnx, None)\n",
    "    input_name = model.get_inputs()[0].name\n",
    "    label_name = model.get_outputs()[0].name\n",
    "    \n",
    "    # variables to monitor model input and output data\n",
    "    inputs_dc = ModelDataCollector(\"Support vector classifier model\", designation=\"inputs\", feature_names=[\"feat1\", \"feat2\", \"feat3\", \"feat4\", \"feat5\", \"feat6\", \"feat7\"])\n",
    "    prediction_dc = ModelDataCollector(\"Support vector classifier model\", designation=\"predictions\", feature_names=[\"weatherprediction\"])\n",
    "\n",
    "    \n",
    "@input_schema('data', NumpyParameterType(np.array([[34.927778, 0.24, 7.3899, 83, 16.1000, 1016.51, 1]])))\n",
    "@output_schema(NumpyParameterType(np.array([0])))\n",
    "def run(data):\n",
    "                try: \n",
    "                    data = scaler.fit_transform(data.reshape(1, 7))\n",
    "                    inputs_dc.collect(data)\n",
    "                    \n",
    "                    # model inference\n",
    "                    result = model.run([label_name], {input_name: data.astype(np.float32)})[0]\n",
    "                    # this call is saving model output data into Azure Blob\n",
    "                    prediction_dc.collect(result)\n",
    "\n",
    "                 \n",
    "                except Exception as e:   \n",
    "                    result = 'error'\n",
    "                    prediction_dc.collect(result)\n",
    "                    \n",
    "                return result.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfad2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fe1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "Environment(name=\"myenv\")\n",
    "\n",
    "env = Environment.get(workspace=ws, name=\"AzureML-Minimal\").clone('myenv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ca5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specyfying conda dependenices\n",
    "\n",
    "for pip_package in [\"numpy\", \"onnxruntime\", \"joblib\", \"azureml-core\", \"azureml-monitoring\", \"azureml-defaults\", \"scikit-learn==0.20.3\", \"inference-schema\", \"inference-schema[numpy-support]\"]:\n",
    "    env.python.conda_dependencies.add_pip_package(pip_package)\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score.py',\n",
    "                                    environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f91e1",
   "metadata": {},
   "source": [
    "## Deployment Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, collect_model_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b73712",
   "metadata": {},
   "source": [
    "## Deploy web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89340717",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(ws, 'model-scaler')\n",
    "model2 = Model(ws, 'support-vector-classifier')\n",
    "\n",
    "service_name = 'weather-aci-prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93857fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Model.deploy(ws, service_name, models=[model1, model2], inference_config=inference_config, deployment_config=deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf441bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b1a85",
   "metadata": {},
   "source": [
    "## Application Insights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b098842a",
   "metadata": {},
   "source": [
    "## Testing the web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4d83c",
   "metadata": {},
   "source": [
    "## Testing with inout from user ( from score.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ac069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_payload = json.dumps({\n",
    "    'data': [[34.927778, 0.24, 7.3899, 83, 16.1000, 1016.51, 1]],\n",
    "    'method': 'predict'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e685481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then delete the service \n",
    "# service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
