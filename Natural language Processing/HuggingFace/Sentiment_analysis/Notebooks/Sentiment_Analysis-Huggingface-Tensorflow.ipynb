{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b72376",
   "metadata": {},
   "source": [
    "Sentiment Analysis with Huggingface transformer and Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9698b",
   "metadata": {},
   "source": [
    "Dataset : https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c7df9",
   "metadata": {},
   "source": [
    "Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.\n",
    "test.tsv contains just phrases. You must assign a sentiment label to each phrase.\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd52ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset will be loaded using kaggle api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6300586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (1.5.12)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from kaggle) (1.26.4)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from kaggle) (4.59.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0474a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a410ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle # after saving the kaggle.json in required path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3f2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a28c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = KaggleApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "666efdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc91e5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.tsv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "api.competition_download_file('sentiment-analysis-on-movie-reviews',\n",
    "                             'test.tsv.zip', path='./')\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1782b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying by creating a new token\n",
    "# it works after creating new token.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afab6d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.tsv.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "api.competition_download_file('sentiment-analysis-on-movie-reviews',\n",
    "                             'train.tsv.zip', path='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d92febff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we have zip files , so extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52118db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82d60177",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./test.tsv.zip','r') as zipref:\n",
    "    zipref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94a3ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('./train.tsv.zip','r') as zipref:\n",
    "    zipref.extractall('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79df972",
   "metadata": {},
   "source": [
    "### This completes data download step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2932e",
   "metadata": {},
   "source": [
    "## Data Preprocessing Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9967eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821b7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b142034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4123d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here there are duplicates\n",
    "# remove duplicates by keeping the first instance\n",
    "\n",
    "# running below code will drop the duplicates\n",
    "# but since the dataset is small so removing it will underfit\n",
    "\n",
    "#df.drop_duplicates(subset=['SentenceId'],keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaf03074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26d62bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c2b768",
   "metadata": {},
   "source": [
    "#### The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6fd2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize its so that we can get token id and attention mask values for\n",
    "# hugging face transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d263cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 156060)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need tensors in form numpy arrays\n",
    "# give seq length and num of samples\n",
    "\n",
    "seq_len = 512\n",
    "num_samples = len(df)\n",
    "\n",
    "seq_len , num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103143db",
   "metadata": {},
   "source": [
    "### Import BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72737f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9033611a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (0.0.19)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: six in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cd9881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe3ba2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (2.6.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.41.1)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce5be969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46c23194",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15293401",
   "metadata": {},
   "source": [
    "### Information about bert-base-cased : \n",
    "https://huggingface.co/bert-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc7f2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(df['Phrase'].to_list(),\n",
    "                  max_length=seq_len,\n",
    "                  truncation=True,\n",
    "                  padding='max_length',\n",
    "                  add_special_tokens=True,\n",
    "                  return_tensors='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faa7baff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4219a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101, 22572, 12148, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids']\n",
    "# this will show all different types of tokens\n",
    "# ex: SEP , CLS , UNK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b2431cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "096aa0c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-837d63ea67df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'movie-ids.npy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'movie-masks.npy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'attention_mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0m\u001b[0;32m    529\u001b[0m                            pickle_kwargs=dict(fix_imports=fix_imports))\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    646\u001b[0m     \"\"\"\n\u001b[0;32m    647\u001b[0m     \u001b[0m_check_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m     \u001b[0m_write_array_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader_data_from_array_1_0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36m_write_array_header\u001b[1;34m(fp, d, version)\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrap_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m     \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrite_array_header_1_0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "# save these arrays as binary files\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with open('movie-ids.npy','w') as f:\n",
    "    np.save(f,tokens['input_ids'])\n",
    "with open('movie-masks.npy','w') as f:\n",
    "    np.save(f,tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee5158c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('movie-ids.npy','wb') as f:\n",
    "    np.save(f,tokens['input_ids'])\n",
    "with open('movie-masks.npy','wb') as f:\n",
    "    np.save(f,tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11091227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need labels for training model\n",
    "# convert them into numpy arrays and save them\n",
    "\n",
    "arr = df['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8b3e1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11d4df44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcd8353c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create one hot encoding\n",
    "# before that create the columns \n",
    "# .max() will check the max value and add +1\n",
    "# here max value is 4 \n",
    "# see in arr ( cell #58)\n",
    "\n",
    "arr.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e5be136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meaning this will be as:\n",
    "\n",
    "# if we have number 3\n",
    "# 3 = [0,0,0,1,0] --> 5 digits : there is 1 at index 3 \n",
    "# this was one-hot encoding for number 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "241ae2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remmebr arr.shape was only 1D but we need it as tensor \n",
    "# so converting this with arr.max()+1\n",
    "\n",
    "labels = np.zeros((num_samples, arr.max()+1))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a34a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice the shape now is 156060,5!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81406ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now create one hot encoding\n",
    "# if we check the value of labels it will be all zeros\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4454566c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so now add 1 where there is num_samples mentioned\n",
    "# this will add 1 where there is a corresponding digit from num_samples\n",
    "labels[np.arange(num_samples), arr] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef3a02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now save this\n",
    "\n",
    "with open('movie-labels.npy','wb') as f:\n",
    "    np.save(f,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a736319",
   "metadata": {},
   "source": [
    "### This completes preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd005a9",
   "metadata": {},
   "source": [
    "### Build Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "024b74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b034e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie-ids.npy','rb') as f:\n",
    "    Xids = np.load(f,allow_pickle=True)\n",
    "with open('movie-labels.npy','rb') as f:\n",
    "    Xlabels = np.load(f,allow_pickle=True)\n",
    "with open('movie-masks.npy','rb') as f:\n",
    "    Xmask = np.load(f,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e842a95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       [  101,   138,  1326, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101,   170, 25247, ...,     0,     0,     0],\n",
       "       [  101, 22572, 12148, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3128d260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 512)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdb24de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.]]),\n",
       " (156060, 5))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xlabels,Xlabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84145ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now take these arrays and create a tensorflow object with tf slicing method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5784b3c8",
   "metadata": {},
   "source": [
    "#### https://www.geeksforgeeks.org/tensorflow-tf-data-dataset-from_tensor_slices/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b6579c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03f1c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 21.0.1 from C:\\Users\\Manjunath\\anaconda3\\lib\\site-packages\\pip (python 3.8)\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip--version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "611f5ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras~=2.6 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.41.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\manjunath\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\manjunath\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --user tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76058f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dataset = tf.data.Dataset.from_tensor_slices((Xids,Xmask,Xlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "892cb366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((512,), (512,), (5,)), types: (tf.int32, tf.int32, tf.float64)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e69367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of ids and masks is 512 \n",
    "# shape of labels is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85c66ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fit data into tensorflow need 2 item tuple\n",
    "# in form of inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63c6c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently there are 3 items : input_ids , masks , lables\n",
    "# so write function a MAP 3 items to 2 items\n",
    "# in this format : {inputs,outputs} --> this is dictionary\n",
    "# inputs = input_ids , attention_masks\n",
    "# outputs = tensors\n",
    "# dict = {inputs,outputs} --> convert 3 items to 2 items bcoz 2 inputs got combined as 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f659e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids,masks,labels):\n",
    "    return {'input_ids':input_ids,\n",
    "           'attention_masks':masks},labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b2f80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply this function to the dataset\n",
    "\n",
    "dataset = dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd8555d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({input_ids: (16, 16, 16, 512), attention_masks: (16, 16, 16, 512)}, (16, 16, 16, 5)), types: ({input_ids: tf.int32, attention_masks: tf.int32}, tf.float64)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5dd3ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MapDataset shapes: ({input_ids: (512,), attention_masks: (512,)}, (5,))\n",
    "# this gives 2 item tuple , but it is still a single tuple!!\n",
    "# one item is input_ids + attention_masks\n",
    "# other item is labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7d5957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22eddecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa0e28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b68bf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({input_ids: (16, 16, 16, 512), attention_masks: (16, 16, 16, 512)}, (16, 16, 16, 5)), types: ({input_ids: tf.int32, attention_masks: tf.int32}, tf.float64)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2cf7bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bcb44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = Xids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c5da2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3146bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7803"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((Xids.shape[0] / batch_size) * split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11132f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int((Xids.shape[0] / batch_size) * split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08d9c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(size)\n",
    "test_ds = dataset.skip(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0dd131c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(train_ds,'train')\n",
    "tf.data.experimental.save(test_ds,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9831ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None),\n",
       "  'attention_masks': TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(16, 16, 16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09613a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec == test_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4a847b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None),\n",
       "  'attention_masks': TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(16, 16, 16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "013dfc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "ds = tf.data.experimental.load('train', element_spec=train_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2d46204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_LoadDataset shapes: ({input_ids: (16, 16, 16, 512), attention_masks: (16, 16, 16, 512)}, (16, 16, 16, 5)), types: ({input_ids: tf.int32, attention_masks: tf.int32}, tf.float64)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db80be8",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "49587aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b9509fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17fbfadc764488bbc19bfe04e831deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "04d536a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "44fbd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 108310272 million parameters !!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1718d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 inputs\n",
    "\n",
    "input_ids = tf.keras.layers.Input(shape=(512,),\n",
    "                                  name='input_ids',\n",
    "                                  dtype='int32')\n",
    "\n",
    "mask = tf.keras.layers.Input(shape=(512,),\n",
    "                                  name='attention_mask',\n",
    "                                  dtype='int32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fab6aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer\n",
    "embeddings = bert.bert(input_ids, attention_mask = mask)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4d7ee59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier head\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(5,activation='softmax', name='outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "03abe756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4162ccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         787456      bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            5125        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 109,102,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79bab5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze bert layer\n",
    "# this is part of transfer learning\n",
    "# https://keras.io/guides/transfer_learning/\n",
    "\n",
    "model.layers[2].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d581c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         787456      bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            5125        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 792,581\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# again running summary\n",
    "# notice the 'Trainable params' --> it has reduced\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "41c88b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for decay rate - https://keras.io/api/optimizers/learning_rate_schedules/exponential_decay/\n",
    "# for optimizers: https://keras.io/api/optimizers/\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=5e-5, decay=1e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "accuracy_score = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe1003",
   "metadata": {},
   "source": [
    "The Dataset.element_spec property allows you to inspect the type of each element component. The property returns a nested structure of tf.TypeSpec objects, matching the structure of the element, which may be a single component, a tuple of components, or a nested tuple of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e963e672",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TensorSpec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-56b3b6757a29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m element_spec = ({'input_ids': TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None),\n\u001b[0m\u001b[0;32m      2\u001b[0m   'attention_masks': TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None)},\n\u001b[0;32m      3\u001b[0m  TensorSpec(shape=(16, 16, 16, 5), dtype=tf.float64, name=None))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TensorSpec' is not defined"
     ]
    }
   ],
   "source": [
    "element_spec = ({'input_ids': TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None),\n",
    "  'attention_masks': TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None)},\n",
    " TensorSpec(shape=(16, 16, 16, 5), dtype=tf.float64, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "16371c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "element_spec = ({'input_ids': tf.TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None),\n",
    "  'attention_masks': tf.TensorSpec(shape=(16, 16, 16, 512), dtype=tf.int32, name=None)},\n",
    " tf.TensorSpec(shape=(16, 16, 16, 5), dtype=tf.float64, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3df75b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "train_ds = tf.data.experimental.load('train', element_spec=element_spec)\n",
    "test_ds = tf.data.experimental.load('test', element_spec=element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e597469a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_LoadDataset shapes: ({input_ids: (16, 16, 16, 512), attention_masks: (16, 16, 16, 512)}, (16, 16, 16, 5)), types: ({input_ids: tf.int32, attention_masks: tf.int32}, tf.float64)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8dbfbc33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\input_spec.py:182 assert_input_compatibility\n        raise ValueError('Missing data for input \"%s\". '\n\n    ValueError: Missing data for input \"attention_mask\". You passed a data dictionary with keys ['input_ids', 'attention_masks']. Expected the following keys: ['input_ids', 'attention_mask']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-243904c96de5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             epochs=3)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3457\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3459\u001b[1;33m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[0;32m   3460\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3379\u001b[0m           expand_composites=True)\n\u001b[0;32m   3380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3381\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3382\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\input_spec.py:182 assert_input_compatibility\n        raise ValueError('Missing data for input \"%s\". '\n\n    ValueError: Missing data for input \"attention_mask\". You passed a data dictionary with keys ['input_ids', 'attention_masks']. Expected the following keys: ['input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=test_ds,\n",
    "            epochs=3)\n",
    "\n",
    "# this gave error because of multiple times shuffling of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352f8eb",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "506922ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sentiment_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: sentiment_model\\assets\n",
      "C:\\Users\\Manjunath\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model.save('sentiment_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876a6c96",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aa7dba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('sentiment_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "31b5e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before predicting do the tokenization\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ef73e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a preprocessing text function\n",
    "\n",
    "def prep_data(text):\n",
    "    tokens = tokenizer(text,\n",
    "                      max_length=512,\n",
    "                      add_special_tokens=True,\n",
    "                      return_tensors='tf')\n",
    "    return {'input_ids':tokens['input_ids'],\n",
    "           'attention_mask':tokens['attention_mask']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c7605747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[  101, 13761,  1110,  1363,   119,   102]])>,\n",
       " 'attention_mask': <tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1]])>}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample text\n",
    "# get token id and attention mask\n",
    "\n",
    "prep_data('Nolan is good.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eb8fc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a preprocessing text function with padding and truncation\n",
    "\n",
    "def prep_data(text):\n",
    "    tokens = tokenizer(text,\n",
    "                      max_length=512,\n",
    "                       truncation=True,\n",
    "                       padding='max_length',\n",
    "                      add_special_tokens=True,\n",
    "                      return_tensors='tf')\n",
    "    return {'input_ids':tokens['input_ids'],\n",
    "           'attention_mask':tokens['attention_mask']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "420e9d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       " array([[  101, 13761,  1110,  1363,   119,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]])>,\n",
       " 'attention_mask': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       " array([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]])>}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample text\n",
    "# get token id and attention mask\n",
    "\n",
    "prep_data('Nolan is good.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440eb191",
   "metadata": {},
   "source": [
    "### Perform predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "acb28916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1856832 , 0.22101137, 0.06506184, 0.09596708, 0.43227655]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(prep_data('Joker is better than Batman'))\n",
    "# they are activations!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4a9bb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict(prep_data('Joker is better than Batman'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "46469881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1856832 , 0.22101137, 0.06506184, 0.09596708, 0.43227655],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dee4d040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now as described in transformer architecture perfrom argmax\n",
    "# for argmax need np\n",
    "# argmax will get highest probability\n",
    "\n",
    "# remmeber to match this with classes from the dataset:\n",
    "# 0 - negative 1 - somewhat negative\n",
    "#2 - neutral \n",
    "#3 - somewhat positive \n",
    "# 4 - positive\n",
    "\n",
    "np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7e9a20cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now perfroming on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6d408d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "31730b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c1cbad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'] = None # create new column where sentiment will be shown\n",
    "# be sure to remove duplicates from TEST DATA!\n",
    "# this is taking loads of time :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c8b69024",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-c0b59d35677b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Phrase'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1749\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1751\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1752\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    tokens = prep_data(row['Phrase'])\n",
    "    probs = model.predict(tokens)\n",
    "    pred = np.argmax(probs)\n",
    "    df.at[i, 'Sentiment'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc7625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to predict \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd795d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again to predict\n",
    "df.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
